import os
import builtins
import math
import argparse
import json
from collections import Counter
from typing import TypedDict, List, Optional
import numpy as np
import pandas as pd
import scipy
import sklearn
from rdkit import Chem
import ase
from  ase.io import read
import autoadsorbate
import torch
import mace
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langchain_core.output_parsers import JsonOutputParser

from src.tools.tools import (
    read_atoms_object, 
    create_fragment_from_plan,
    populate_surface_with_fragment,
    relax_atoms, 
    save_ase_atoms,
    analyze_relaxation_results,
)
from src.agent.prompts import PLANNER_PROMPT

MAX_RETRIES = 4

# --- 1. å®šä¹‰æ™ºèƒ½ä½“çŠ¶æ€ (Agent State) ---
class AgentState(TypedDict):
    smiles: str
    slab_path: str
    surface_composition: Optional[List[str]]
    user_request: str
    plan: Optional[dict]
    validation_error: Optional[str]
    messages: List[BaseMessage]
    analysis_json: Optional[str]
    history: List[str]

# --- 2. è®¾ç½®ç¯å¢ƒå’Œ LLM ---
load_dotenv()

if not os.environ.get("GOOGLE_API_KEY"):
    raise ValueError("GOOGLE_API_KEY environment variable not set.")
# if not os.environ.get("OPENROUTER_API_KEY"):
#     raise ValueError("OPENROUTER_API_KEY environment variable not set.")

def get_llm():
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", 
        temperature=0.0, 
        max_tokens=4096, 
        timeout=120, 
    )
    # llm = ChatOpenAI(
    #     openai_api_base="https://openrouter.ai/api/v1",
    #     openai_api_key=os.getenv("OPENROUTER_API_KEY"),
    #     model="google/gemini-2.5-pro",
    #     streaming=False, 
    #     temperature=0.0,
    #     max_tokens=4096, 
    #     timeout=120, 
    #     seed=42
    # )
    return llm

# --- 3. å®šä¹‰ LangGraph èŠ‚ç‚¹ ---
def pre_processor_node(state: AgentState) -> dict:
    """
    åœ¨è§„åˆ’å‰è¿è¡Œï¼Œè¯»å–Slabæ–‡ä»¶ä»¥æå–è¡¨é¢æˆåˆ†ã€‚
    """
    print("--- ğŸ”¬ è°ƒç”¨ Pre-Processor èŠ‚ç‚¹ ---")
    try:
        slab_atoms = read(state["slab_path"])
        # è·å–æ‰€æœ‰åŸå­çš„åŒ–å­¦ç¬¦å·
        symbols = slab_atoms.get_chemical_symbols()
        # è·å–å”¯ä¸€çš„åŒ–å­¦ç¬¦å·åˆ—è¡¨, æŒ‰å‡ºç°æ¬¡æ•°æ’åº
        # (ä¾‹å¦‚ ['Cu', 'O'] è€Œä¸æ˜¯ ['O', 'Cu'])
        composition = [item[0] for item in Counter(symbols).most_common()]

        print(f"--- ğŸ”¬ æˆåŠŸè¯»å–Slabã€‚æˆåˆ†: {composition} ---")
        return {"surface_composition": composition}
    except Exception as e:
        error_message = f"False, åŸºç¡€ Slab æ–‡ä»¶ '{state['slab_path']}' æ— æ³•è¢« ASE è¯»å–: {e}"
        print(f"--- éªŒè¯å¤±è´¥: {error_message} ---")
        # è¿™æ˜¯ä¸€ä¸ªè‡´å‘½é”™è¯¯ï¼Œæˆ‘ä»¬è®¾ç½® validation_error æ¥åœæ­¢å·¥ä½œæµ
        return {
            "validation_error": error_message,
            "surface_composition": None
        }

def solution_planner_node(state: AgentState) -> dict:
    print("--- ğŸ§  è°ƒç”¨ Planner èŠ‚ç‚¹ ---")
    llm = get_llm()
    messages = []
    
    prompt_input = {
        "smiles": state["smiles"],
        "slab_xyz_path": state["slab_path"],
        "surface_composition": state.get("surface_composition", "æœªçŸ¥"),
        "user_request": state["user_request"],
        "history": "\n".join(state["history"]) if state.get("history") else "æ— ",
        "MAX_RETRIES": MAX_RETRIES
    }
    
    if state.get("validation_error"):
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))
        messages.append(AIMessage(content=json.dumps(state.get("plan", "{}"))))
        messages.append(HumanMessage(content=f"ä½ çš„æ–¹æ¡ˆå­˜åœ¨é€»è¾‘é”™è¯¯: {state['validation_error']}. è¯·é‡æ–°è§„åˆ’ä¸€ä¸ªæ–°æ–¹æ¡ˆã€‚"))
    else:
        if state.get("history"):
            print(f"--- ğŸ§  Planner: æ£€æµ‹åˆ°å¤±è´¥å†å²ï¼Œæ­£åœ¨é‡è¯•... ---")
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))

    response = llm.invoke(messages)
    
    try:
        parser = JsonOutputParser()

        content_str = response.content
        if content_str.startswith("```json"):
            content_str = content_str[7:-3].strip()
        
        plan_json = parser.parse(content_str)
        print(f"--- ğŸ§  Planner æ–¹æ¡ˆå·²ç”Ÿæˆ ---")
        return {
            "plan": plan_json,
            "messages": [AIMessage(content=response.content)],
            "validation_error": None
        }
    except Exception as e:
        print(f"--- ğŸ›‘ Planner è¾“å‡º JSON è§£æå¤±è´¥: {e} ---")
        print(f"--- åŸå§‹è¾“å‡º: {response.content} ---")
        return {
            "plan": None,
            "validation_error": f"False, Planner è¾“å‡ºæ ¼å¼é”™è¯¯: {e}. è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¾“å‡ºã€‚",
            "messages": [AIMessage(content=response.content)]
        }

def plan_validator_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 2: Python éªŒè¯å™¨ """
    print("--- ğŸ è°ƒç”¨ Python éªŒè¯å™¨èŠ‚ç‚¹ ---")

    try:
        # ä½¿ç”¨ state["smiles"] (æ¥è‡ªåˆå§‹è¾“å…¥) è€Œä¸æ˜¯ plan ä¸­çš„ä»»ä½•å†…å®¹
        mol = Chem.MolFromSmiles(state["smiles"])
        if not mol:
            raise ValueError(f"RDKit è¿”å› Noneã€‚SMILES å¯èƒ½æ— æ•ˆæˆ–åŒ…å« RDKit æ— æ³•å¤„ç†çš„ä»·æ€ã€‚")
    except Exception as e:
        error = f"False, åŸºç¡€ SMILES å­—ç¬¦ä¸² '{state['smiles']}' æ— æ³•è¢« RDKit è§£æã€‚è¿™æ˜¯ä¸€ä¸ªæ— æ³•ä¿®å¤çš„é”™è¯¯ã€‚è¯·æ£€æŸ¥ SMLIESã€‚é”™è¯¯: {e}"
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        # è¿™æ˜¯ä¸€ä¸ªè‡´å‘½é”™è¯¯ï¼›æˆ‘ä»¬åº”è¯¥åœæ­¢é‡è¯•ã€‚
        # æˆ‘ä»¬é€šè¿‡è®¾ç½®ä¸€ä¸ªç‰¹æ®Šçš„ validation_error æ¥é€šçŸ¥è·¯ç”±
        # æ³¨æ„ï¼šç†æƒ³æƒ…å†µä¸‹ï¼Œå›¾åº”è¯¥æœ‰ä¸€ä¸ª "terminal_failure" çŠ¶æ€ï¼Œ
        # ä½†ç›®å‰æˆ‘ä»¬åªèƒ½è¿”å›ç»™ plannerï¼Œå¹¶æœŸæœ›å®ƒåœ¨ N æ¬¡ååœæ­¢ã€‚
        return {"validation_error": error, "plan": None} # æ¸…é™¤ plan

    plan_json = state.get("plan")
    if plan_json is None:
        print("--- éªŒè¯å¤±è´¥: Planneræœªèƒ½ç”Ÿæˆæœ‰æ•ˆJSONã€‚---")
        return {"validation_error": state.get("validation_error", "False, Planner èŠ‚ç‚¹æœªèƒ½ç”Ÿæˆ JSONã€‚")}
    
    if "solution" not in plan_json:
        error = "False, æ–¹æ¡ˆ JSON ä¸¢å¤± 'solution' é”®ã€‚"
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
        
    plan = plan_json.get("solution", {})
    if not plan:
        error = "False, æ–¹æ¡ˆ JSON ä¸¢å¤±æˆ–æ ¼å¼é”™è¯¯ï¼ˆ'solution' é”®ä¸ºç©ºï¼‰ã€‚"
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}

    orientation = plan.get("orientation", "")
    site_type = plan.get("site_type", "")
    surf_atoms = plan.get("surface_binding_atoms", [])
    ads_indices = plan.get("adsorbate_binding_indices", [])
    if site_type == "ontop" and len(surf_atoms) != 1:
        error = f"False, Rule 1: Python check failed. site_type is 'ontop' but surface_binding_atoms has {len(surf_atoms)} members (should be 1)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if site_type == "bridge" and len(surf_atoms) != 2:
        error = f"False, Rule 1: Python check failed. site_type is 'bridge' but surface_binding_atoms has {len(surf_atoms)} members (should be 2)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if site_type == "hollow" and len(surf_atoms) < 3: 
        error = f"False, Rule 1: Python check failed. site_type is 'hollow' but surface_binding_atoms has {len(surf_atoms)} members (should be >= 3)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if orientation == "end-on" and len(ads_indices) != 1:
        error = f"False, Rule 2: Python check failed. orientation is 'end-on' but adsorbate_binding_indices has {len(ads_indices)} members (should be 1)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if orientation == "side-on":
        if len(ads_indices) != 2:
            error = f"False, Rule 2: Python check failed. orientation is 'side-on' but adsorbate_binding_indices has {len(ads_indices)} members (should be 2)."
            print(f"--- éªŒè¯å¤±è´¥: {error} ---")
            return {"validation_error": error}
        elif site_type not in ["bridge", "hollow"]:
            error = f"False, Rule 3: Python check failed. orientation 'side-on' is physically incompatible with site_type '{site_type}'. 'side-on' must use 'bridge' or 'hollow'."
            print(f"--- éªŒè¯å¤±è´¥: {error} ---")
            return {"validation_error": error}
    print("--- éªŒè¯æˆåŠŸ ---")
    return {"validation_error": None}

def tool_executor_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 4: Tool Executor """
    print("--- ğŸ› ï¸ è°ƒç”¨ Tool Executor èŠ‚ç‚¹ ---")
    
    plan_solution = state["plan"].get("solution", {})

    if not plan_solution:
        error_message = "Tool Executor å¤±è´¥: 'plan' ä¸­ç¼ºå°‘ 'solution' å­—å…¸ã€‚"
        print(f"--- ğŸ›‘ {error_message} ---")
        return {
            "messages": [ToolMessage(content=error_message, tool_call_id="tool_executor")],
            "analysis_json": json.dumps({"status": "error", "message": error_message})
        }

    slab_path = state["slab_path"]
    tool_logs = []
    analysis_json = None
    
    try:
        slab_atoms = read_atoms_object(slab_path)
        tool_logs.append(f"æˆåŠŸ: å·²ä» {slab_path} è¯»å– slab åŸå­ã€‚")
    
        # --- è®¡ç®—å‚è€ƒæ€èƒ½é‡ (E_surface å’Œ E_adsorbate) ---
        # 1. åˆå§‹åŒ–ä¸€ä¸ªç»Ÿä¸€çš„è®¡ç®—å™¨å’Œ *ä¸€è‡´çš„* å¼›è±«å‚æ•°
        try:
            import torch
            from ase import units
            from ase.constraints import FixAtoms
            from ase.md.langevin import Langevin
            from ase.md.velocitydistribution import MaxwellBoltzmannDistribution
            from ase.optimize import BFGS
            from mace.calculators import mace_mp
            
            # ç»Ÿä¸€å®šä¹‰å¼›è±«å‚æ•°
            opt_fmax = 0.05
            opt_steps = 500
            md_steps = 20
            md_temp = 150.0
            mace_model = "small"
            mace_device = "cuda" if torch.cuda.is_available() else "cpu"
            
            temp_calc = mace_mp(model=mace_model, device=mace_device, default_dtype='float32', dispersion=True)

        except Exception as e_calc:
            raise ValueError(f"Failed to initialize MACE calculator: {e_calc}")

        # 2. è®¡ç®— E_surface
        try:
            e_surf_atoms = slab_atoms.copy()
            e_surf_atoms.calc = temp_calc

            # *** åº”ç”¨ä¸ relax_atoms *å®Œå…¨ä¸€è‡´* çš„çº¦æŸ ***
            # tools.py::relax_atoms å›ºå®šäº† *æ‰€æœ‰* è¡¨é¢åŸå­ã€‚
            constraint = FixAtoms(indices=list(range(len(e_surf_atoms))))
            e_surf_atoms.set_constraint(constraint)

            print(f"--- ğŸ› ï¸ æ­£åœ¨è®¡ç®—è£¸è¡¨é¢çš„å•ç‚¹èƒ½ (æ‰€æœ‰åŸå­å·²å›ºå®š)... ---")

            E_surface = e_surf_atoms.get_potential_energy() # è¿™ç°åœ¨æ˜¯ä¸€ä¸ªå•ç‚¹èƒ½
            tool_logs.append(f"Success: E_surface = {E_surface:.4f} eVã€‚")
            
        except Exception as e_surf_err:
            raise ValueError(f"Failed to calculate E_surface: {e_surf_err}")
    
        fragment_object = create_fragment_from_plan(
            original_smiles=state["smiles"],
            binding_atom_indices=plan_solution.get("adsorbate_binding_indices"),
            orientation=plan_solution.get("orientation"),
            to_initialize=plan_solution.get("conformers_per_site_cap", 5)
        )
        tool_logs.append(f"Success: Created fragment object from plan (SMILES: {state['smiles']}).")

        try:
            adsorbate_only_atoms = fragment_object.conformers[0].copy()
            
            # ç§»é™¤æ ‡è®°
            if adsorbate_only_atoms.info["smiles"] == "Cl":
                del adsorbate_only_atoms[0]
            elif adsorbate_only_atoms.info["smiles"] == "S1S":
                del adsorbate_only_atoms[:2]
                
            adsorbate_only_atoms.calc = temp_calc
            adsorbate_only_atoms.set_cell([20, 20, 20]) 
            adsorbate_only_atoms.center()
            
            print(f"--- ğŸ› ï¸ æ­£åœ¨å¼›è±«å­¤ç«‹çš„ {state['smiles']} åˆ†å­... ---")

            # *** åº”ç”¨ *ä¸€è‡´* çš„å¼›è±«åè®® ***
            
            # åè®® 1: MD é¢„çƒ­ (ä¸ relax_atoms ä¸€è‡´)
            if md_steps > 0:
                MaxwellBoltzmannDistribution(adsorbate_only_atoms, temperature_K=md_temp)
                dyn_md_ads = Langevin(adsorbate_only_atoms, 1 * units.fs, temperature_K=md_temp, friction=0.01)
                dyn_md_ads.run(md_steps)
                
            # åè®® 2: BFGS ä¼˜åŒ– (ä¸ relax_atoms ä¸€è‡´)
            BFGS(adsorbate_only_atoms).run(fmax=opt_fmax, steps=opt_steps)
            
            E_adsorbate = adsorbate_only_atoms.get_potential_energy()
            tool_logs.append(f"æˆåŠŸ: E_adsorbate = {E_adsorbate:.4f} eVã€‚")
            
        except Exception as e_ads_err:
            raise ValueError(f"è®¡ç®— E_adsorbate å¤±è´¥: {e_ads_err}")

        generated_traj_file = populate_surface_with_fragment(
            slab_atoms=slab_atoms,
            fragment_object=fragment_object,
            plan_solution=plan_solution
        )
        tool_logs.append(f"æˆåŠŸ: å·²å°†ç‰‡æ®µæ”¾ç½®åœ¨ slab ä¸Šã€‚æ„å‹ä¿å­˜åœ¨: {generated_traj_file}")

        initial_conformers = read(generated_traj_file, index=":")
        if not initial_conformers or len(initial_conformers) == 0:
            raise ValueError(f"populate_surface_with_fragment æœªèƒ½ç”Ÿæˆä»»ä½•æ„å‹ (è½¨è¿¹æ–‡ä»¶ä¸ºç©º: {generated_traj_file})ã€‚")
        
        print("--- â³ å¼€å§‹ç»“æ„å¼›è±«... ---")
        slab_indices = list(range(len(slab_atoms)))
        relax_n = plan_solution.get("relax_top_n", 1)
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"--- ğŸ› ï¸ MACE å°†ä½¿ç”¨è®¾å¤‡: {device} ---")

        final_traj_file = relax_atoms(
            atoms_list=list(initial_conformers),
            slab_indices=slab_indices,
            relax_top_n=relax_n,
            fmax=opt_fmax,
            steps=opt_steps,
            md_steps=md_steps,
            md_temp=md_temp,
            mace_model=mace_model,
            mace_device=mace_device
        )
        tool_logs.append(f"æˆåŠŸ: ç»“æ„å¼›è±«å®Œæˆ (å¼›è±«äº† Top {relax_n})ã€‚è½¨è¿¹ä¿å­˜åœ¨ '{final_traj_file}'ã€‚")
        
        print("--- ğŸ”¬ è°ƒç”¨åˆ†æå·¥å…·... ---")
        analysis_json_str = analyze_relaxation_results(
            relaxed_trajectory_file=final_traj_file,
            slab_atoms=slab_atoms,
            original_smiles=state["smiles"],
            binding_atom_indices=plan_solution.get("adsorbate_binding_indices"),
            orientation=plan_solution.get("orientation"),
            e_surface_ref=E_surface,
            e_adsorbate_ref=E_adsorbate
        )
        tool_logs.append(f"æˆåŠŸ: åˆ†æå·¥å…·å·²æ‰§è¡Œã€‚")
        print(f"--- ğŸ”¬ åˆ†æç»“æœ: {analysis_json_str} ---")
        analysis_json = json.loads(analysis_json_str)
        
    except ValueError as e: # ç‰¹åˆ«æ•è· _get_fragment çš„å¤±è´¥
        if "RDKit" in str(e):
            # è¿™æ˜¯ä¸€ä¸ªè‡´å‘½çš„ã€ä¸å¯é‡è¯•çš„ SMILES é”™è¯¯
            error_message = f"è‡´å‘½é”™è¯¯ï¼šRDKit æ— æ³•ä¸º SMILES '{state['smiles']}' ç”Ÿæˆæ„è±¡: {e}"
            print(f"--- ğŸ›‘ {error_message} ---")
            analysis_json = {"status": "fatal_error", "message": error_message}
            # ä¸è¦æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›è¿™ä¸ªç‰¹æ®Šçš„ analysis_json
            return {
                "messages": [ToolMessage(content=error_message, tool_call_id="tool_executor")],
                "analysis_json": json.dumps(analysis_json)
            }
        else:
            raise e # é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚æ•è·

    except Exception as e:
        error_message = str(e)
        print(f"--- ğŸ›‘ å·¥å…·æ‰§è¡Œå¤±è´¥: {error_message} ---")
        tool_logs.append(f"Error during tool execution: {error_message}")
        analysis_json = {"status": "error", "message": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {error_message}"}
        
    return {
        "messages": [ToolMessage(content="\n".join(tool_logs), tool_call_id="tool_executor")],
        "analysis_json": json.dumps(analysis_json)
    }

def final_analyzer_node(state: AgentState) -> dict:
    """ 
    èŠ‚ç‚¹ 5: Final Analyzer
    æåº¦ä¸¥æ ¼çš„å¤±è´¥æç¤ºè¯ï¼Œé˜²æ­¢å¹»è§‰ã€‚
    """
    print("--- âœï¸ è°ƒç”¨ Final Analyzer èŠ‚ç‚¹ ---")
    llm = get_llm()
    analysis_data = {}
    try:
        analysis_json_str = state.get("analysis_json")
        if not analysis_json_str:
            analysis_data = {"status": "error", "message": "åˆ†æ JSON ä¸¢å¤±æˆ–ä¸ºç©ºã€‚"}
        else:
            analysis_data = json.loads(analysis_json_str)
    except json.JSONDecodeError as e:
        print(f"--- ğŸ›‘ Final Analyzer: JSON è§£æå¤±è´¥ {e} ---")
        print(f"--- åŸå§‹å­—ç¬¦ä¸²: {state.get('analysis_json')} ---")
        analysis_data = {"status": "error", "message": f"Analysis JSON was corrupted: {e}"}
    
    if analysis_data.get("status") == "success" and analysis_data.get("is_covalently_bound", False):
        final_prompt = """
        ä½ æ˜¯ä¸€åè®¡ç®—åŒ–å­¦ä¸“å®¶ã€‚
        ä½ çš„è§„åˆ’å’Œè®¡ç®—ä»»åŠ¡å·²æˆåŠŸæ‰§è¡Œï¼Œå¹¶ä¸”è‡ªåŠ¨åŒ–åˆ†æå·¥å…·å·²è¿”å›äº† *åŸºäºäº‹å®* çš„æ•°æ®ã€‚

        **ä½ çš„åŸå§‹è§„åˆ’ (ä½ å½“åˆçš„æ„å›¾):**
        {plan}

        **è‡ªåŠ¨åŒ–åˆ†æå·¥å…·è¿”å›çš„çœŸå®æ•°æ® (å®¢è§‚äº‹å®):**
        {analysis_json}

        **ä½ çš„ä»»åŠ¡:**
        1.  **è§£è¯»æ•°æ®:** æŸ¥çœ‹ `analysis_json`ã€‚`is_covalently_bound` æ˜¯ True è¿˜æ˜¯ Falseï¼Ÿ`most_stable_energy_eV` å’Œ `final_bond_distance_A` æ˜¯å¤šå°‘ï¼Ÿ
        2.  **å›ç­”è¯·æ±‚:** æ ¹æ®è¿™ä¸ª *çœŸå®æ•°æ®*ï¼ˆè€Œä¸æ˜¯çŒœæµ‹ï¼‰ï¼Œå›ç­”ç”¨æˆ·çš„åŸå§‹è¯·æ±‚ï¼š
            '{user_request}'
        3.  **æä¾›å…³é”®ä¿¡æ¯:** æŠ¥å‘Šæœ€ç¨³å®šçš„èƒ½é‡ã€é”®é•¿å’Œä¿å­˜çš„æœ€ä½³ç»“æ„æ–‡ä»¶å (`best_structure_file`)ã€‚
        4.  **ç¦æ­¢å¹»è§‰:** ä½ çš„æŠ¥å‘Šå¿…é¡» 100% å»ºç«‹åœ¨ä¸Šè¿° JSON æ•°æ®çš„å®¢è§‚äº‹å®ä¸Šã€‚
        """
        plan_str = json.dumps(state.get("plan", "{}"))
        prompt = final_prompt.format(
            plan=plan_str, 
            analysis_json=state["analysis_json"], 
            user_request=state["user_request"]
        )
    
    else:
        fail_message = analysis_data.get("message", "æœªçŸ¥çš„åˆ†æé”™è¯¯ã€‚")
        if analysis_data.get("status") == "success" and not analysis_data.get("is_covalently_bound", False):
             fail_message = f"åˆ†æå®Œæˆï¼Œä½†å¸é™„ç‰©æœªä¸è¡¨é¢é”®åˆ (is_covalently_bound: false)ã€‚æœ€ç»ˆè·ç¦»: {analysis_data.get('final_bond_distance_A', 'N/A')} Ã…ã€‚"
        
        final_prompt = """
        ä½ æ˜¯ä¸€ä¸ªé”™è¯¯æŠ¥å‘ŠåŠ©æ‰‹ã€‚
        è®¡ç®—ä»»åŠ¡æ‰§è¡Œå¤±è´¥æˆ–æœªèƒ½æ‰¾åˆ°ç¨³å®šçš„é”®åˆæ„å‹ã€‚

        **ä½ çš„å”¯ä¸€ä»»åŠ¡:**
        1.  ç¤¼è²Œåœ°å‘ŠçŸ¥ç”¨æˆ·è®¡ç®—æ¨¡æ‹Ÿå¤±è´¥æˆ–æœªæ‰¾åˆ°ç¨³å®šæ„å‹ã€‚
        2.  **é€å­—** æŠ¥å‘Š `analysis_json` ä¸­çš„ "message" å­—æ®µï¼Œæˆ–è€…æŠ¥å‘Šæœªé”®åˆçš„äº‹å®ã€‚
        3.  **ä¸¥æ ¼ç¦æ­¢** å°è¯•å›ç­”ç”¨æˆ·çš„åŸå§‹ç§‘å­¦é—®é¢˜ã€‚
        4.  **ä¸¥æ ¼ç¦æ­¢** çŒœæµ‹å¤±è´¥çš„åŸå› æˆ–æä¾›ä»»ä½•ç§‘å­¦å»ºè®®ã€‚
        
        **å·¥å…·æ‰§è¡Œé”™è¯¯æ—¥å¿— (å¿…é¡»æŠ¥å‘Š):**
        {fail_message_to_report}
        
        **ç¤ºä¾‹è¾“å‡º:**
        "æŠ±æ­‰ï¼Œè®¡ç®—æ¨¡æ‹Ÿæ‰§è¡Œå¤±è´¥ã€‚è‡ªåŠ¨åŒ–å·¥å…·æŠ¥å‘Šäº†ä»¥ä¸‹é”™è¯¯ï¼š<fail_message_to_report>"
        """
        prompt = final_prompt.format(
            fail_message_to_report=fail_message
        )
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    print("--- ğŸ æµç¨‹ç»“æŸ ---")
    return {"messages": [AIMessage(content=response.content)]}

# --- 4. å®šä¹‰å›¾çš„é€»è¾‘æµ (Edges) ---
def route_after_validation(state: AgentState) -> str:
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 1 (éªŒè¯å™¨) ---")
    if state.get("validation_error"):
        print(f"--- å†³ç­–: æ–¹æ¡ˆå¤±è´¥ï¼Œè¿”å›è§„åˆ’ ---")
        return "planner"
    else:
        print(f"--- å†³ç­–: æ–¹æ¡ˆé€šè¿‡ï¼Œå‰å¾€æ‰§è¡Œ ---")
        return "tool_executor"

import json # ç¡®ä¿ json å·²å¯¼å…¥
...

def route_after_analysis(state: AgentState) -> str:
    """
    æ£€æŸ¥è®¡ç®—ç»“æœï¼Œè®°å½•æˆåŠŸæˆ–å¤±è´¥ï¼Œå¹¶å§‹ç»ˆè¿”å›è§„åˆ’å™¨ç»§ç»­æœç´¢ã€‚
    åªæœ‰åœ¨è¾¾åˆ°é‡è¯•ä¸Šé™æ—¶æ‰åœæ­¢ã€‚
    """
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 3 (åˆ†æå™¨) ---")
    current_history = state.get("history", [])
    history_entry = ""
    try:
        analysis_data = json.loads(state.get("analysis_json", "{}"))
        status = analysis_data.get("status")

        if status == "fatal_error":
            print(f"--- å†³ç­–: è‡´å‘½é”™è¯¯ã€‚æµç¨‹ç»“æŸã€‚ ---")
            history_entry = f"è‡´å‘½é”™è¯¯: {analysis_data.get('message', 'æœªçŸ¥è‡´å‘½é”™è¯¯ã€‚')}"
            return "end"

        is_bound = analysis_data.get("is_covalently_bound", False) 
        plan_str = json.dumps(state.get("plan", "{}"))

        if status == "success" and is_bound:
            # --- æˆåŠŸé€»è¾‘ ---
            energy = analysis_data.get("most_stable_energy_eV", "N/A")
            history_entry = f"æˆåŠŸçš„å°è¯•: Plan={plan_str}, Result=é”®åˆæˆåŠŸ, èƒ½é‡={energy:.4f} eVã€‚"
            print(f"--- å†³ç­–: æ‰¾åˆ°ç¨³å®šé”®åˆ (E={energy:.4f} eV)ã€‚è®°å½•å¹¶è¿”å›è§„åˆ’å™¨ç»§ç»­æœç´¢... ---")

        else:
            # --- å¤±è´¥é€»è¾‘ ---
            fail_reason = analysis_data.get("message", "è®¡ç®—å¤±è´¥æˆ–æœªé”®åˆã€‚")
            if status == "success" and not is_bound:
                if "atom_1" in analysis_data and "atom_2" in analysis_data: # side-on
                    a1_dist = analysis_data["atom_1"].get("distance_A", "N/A")
                    a1_bound = analysis_data["atom_1"].get("is_bound", False)
                    a2_dist = analysis_data["atom_2"].get("distance_A", "N/A")
                    a2_bound = analysis_data["atom_2"].get("is_bound", False)
                    fail_reason = f"åˆ†æå®Œæˆ (side-on)ï¼Œä½†æœªå®Œå…¨é”®åˆã€‚Atom 1 è·ç¦»: {a1_dist} Ã… (Bound: {a1_bound}), Atom 2 è·ç¦»: {a2_dist} Ã… (Bound: {a2_bound})."
                
                elif "final_bond_distance_A" in analysis_data: # end-on
                    dist = analysis_data.get("final_bond_distance_A", "N/A")
                    fail_reason = f"åˆ†æå®Œæˆ (end-on)ï¼Œä½†å¸é™„ç‰©æœªä¸è¡¨é¢é”®åˆã€‚æœ€ç»ˆè·ç¦»: {dist} Ã…ã€‚"
                
                else:
                    fail_reason = analysis_data.get("message", "åˆ†æå®Œæˆï¼Œä½† is_covalently_bound ä¸º falseã€‚")

            history_entry = f"å¤±è´¥çš„å°è¯•: Plan={plan_str}, Result={fail_reason}"
            print(f"--- å†³ç­–: è®¡ç®—å¤±è´¥ ({fail_reason})ã€‚è®°å½•å¹¶è¿”å›è§„åˆ’å™¨é‡è¯•ã€‚ ---")

    except Exception as e:
        print(f"--- å†³ç­–: åˆ†æè·¯ç”±å¤±è´¥ ({e})ã€‚è¿”å›è§„åˆ’å™¨é‡è¯•ã€‚ ---")
        history_entry = f"åˆ†æè·¯ç”±å¤±è´¥: {e}"

    # --- ç»Ÿä¸€çš„è·¯ç”±é€»è¾‘ ---
    current_history.append(history_entry)
    state["history"] = current_history

    if len(current_history) > MAX_RETRIES:
        print(f"--- å†³ç­–: å·²è¾¾åˆ° {len(current_history)} æ¬¡å°è¯•ä¸Šé™ã€‚æµç¨‹ç»“æŸã€‚ ---")
        return "end" # è¾¾åˆ°ä¸Šé™ï¼Œåœæ­¢
    
    return "planner" # æœªè¾¾åˆ°ä¸Šé™ï¼Œç»§ç»­æœç´¢

# --- 5. æ„å»ºå¹¶ç¼–è¯‘å›¾ (Graph) ---
def get_agent_executor():
    """ æ„å»ºå¹¶ç¼–è¯‘ Adsorb-Agent çŠ¶æ€æœºå›¾ã€‚"""
    workflow = StateGraph(AgentState)
    workflow.add_node("pre_processor", pre_processor_node)
    workflow.add_node("planner", solution_planner_node)
    workflow.add_node("plan_validator", plan_validator_node) 
    workflow.add_node("tool_executor", tool_executor_node)
    workflow.add_node("final_analyzer", final_analyzer_node)
    workflow.set_entry_point("pre_processor")
    workflow.add_edge("pre_processor", "planner")
    workflow.add_edge("planner", "plan_validator")
    workflow.add_edge("tool_executor", "final_analyzer")
    workflow.add_conditional_edges(
        "plan_validator",
        route_after_validation,
        {"tool_executor": "tool_executor", "planner": "planner"}
    )
    workflow.add_conditional_edges(
        "final_analyzer",
        route_after_analysis,
        {"planner": "planner", "end": END}
    )
    return workflow.compile()

# --- 6. è¿è¡Œç¨‹åº ---
def _prepare_initial_state(smiles: str, slab_path: str, user_request: str) -> AgentState:
    return {
        "smiles": smiles,
        "slab_path": slab_path,
        "user_request": user_request,
        "plan": None,
        "validation_error": None,
        "messages": [HumanMessage(content=f"SMILES: {smiles}\nSLAB: {slab_path}\nREQUEST: {user_request}")],
        "analysis_json": None,
        "history": []
    }

def parse_args():
    parser = argparse.ArgumentParser(description="Run the Adsorb-Agent.")
    parser.add_argument("--smiles", type=str, required=True, help="SMILES string.")
    parser.add_argument("--slab_path", type=str, required=True, help="Path to the slab .xyz file.")
    parser.add_argument("--user_request", type=str, default="Find a stable adsorption configuration.", help="User's request.")
    return parser.parse_args()

def main_cli():
    args = parse_args()
    if not os.path.exists('./outputs'):
        os.makedirs('./outputs')
    initial_state = _prepare_initial_state(args.smiles, args.slab_path, args.user_request)
    
    agent_executor = get_agent_executor()
    print("\n--- ğŸš€ Adsorb-Agent å·²å¯åŠ¨ ---\n")
    final_state = None
    for chunk in agent_executor.stream(initial_state, stream_mode="values"):
        final_state = chunk
        if "messages" in final_state and final_state["messages"]:
            last_message = final_state["messages"][-1]
            if isinstance(last_message, (AIMessage, ToolMessage)):
                print("\n---")
                print(f"[{last_message.type}]")
                print(last_message.content)
                print("---\n")
    print("\n--- ğŸ Adsorb-Agent ä»»åŠ¡å®Œæˆ ---\n")
    print("æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
    if final_state and "messages" in final_state:
        for msg in reversed(final_state["messages"]):
            if isinstance(msg, AIMessage):
                print(msg.content)
                break
        else:
             print("æœªæ‰¾åˆ°æœ€ç»ˆ AI æ¶ˆæ¯ã€‚")

if __name__ == '__main__':
    exec_globals = builtins.__dict__.copy()
    exec_globals.update({
        "np": np, "pd": pd, "scipy": scipy, "sklearn": sklearn, "math": math,
        "ase": ase, "autoadsorbate": autoadsorbate, "torch": torch, "mace": mace,
    })
    
    main_cli()