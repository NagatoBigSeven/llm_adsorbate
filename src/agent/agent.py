import os
import builtins
import contextlib
import io
import math
import argparse
import json
from typing import TypedDict, List, Optional, Any
import numpy as np
import pandas as pd
import scipy
import sklearn
import ase
import autoadsorbate
import torch
import mace
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langchain_core.output_parsers import JsonOutputParser

from src.tools.tools import (
    read_atoms_object, 
    get_sites_from_atoms, 
    get_fragment, 
    get_ads_slab, 
    relax_atoms, 
    save_ase_atoms,
    analyze_relaxation_results,
    generate_surrogate_smiles
)
from src.agent.prompts import PLANNER_PROMPT

# --- 1. å®šä¹‰æ™ºèƒ½ä½“çŠ¶æ€ (Agent State) ---
class AgentState(TypedDict):
    smiles: str
    slab_path: str
    user_request: str
    plan: Optional[dict]
    validation_error: Optional[str]
    messages: List[BaseMessage]
    analysis_json: Optional[str]
    surrogate_smiles: Optional[str] 

# --- 2. è®¾ç½®ç¯å¢ƒå’Œ LLM ---
load_dotenv()

if not os.environ.get("OPENROUTER_API_KEY"):
    raise ValueError("OPENROUTER_API_KEY environment variable not set.")

def get_llm():
    llm = ChatOpenAI(
        openai_api_base="https://openrouter.ai/api/v1",
        openai_api_key=os.getenv("OPENROUTER_API_KEY"),
        model="ibm-granite/granite-4.0-h-micro",
        streaming=False, 
        max_completion_tokens=20000, 
        request_timeout=600, 
        seed=420
    )
    return llm

# --- 3. å®šä¹‰ LangGraph èŠ‚ç‚¹ (Nodes) ---
def solution_planner_node(state: AgentState) -> dict:
    print("--- ğŸ§  è°ƒç”¨ Planner èŠ‚ç‚¹ ---")
    llm = get_llm()
    messages = []
    
    prompt_input = {
        "smiles": state["smiles"],
        "slab_xyz_path": state["slab_path"],
        "user_request": state["user_request"]
    }
    
    if state.get("validation_error"):
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))
        messages.append(AIMessage(content=json.dumps(state.get("plan", "{}"))))
        messages.append(HumanMessage(content=f"ä½ çš„æ–¹æ¡ˆå­˜åœ¨é€»è¾‘é”™è¯¯: {state['validation_error']}. è¯·é‡æ–°è§„åˆ’ä¸€ä¸ªæ–°æ–¹æ¡ˆã€‚"))
    else:
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))

    response = llm.invoke(messages)
    
    try:
        parser = JsonOutputParser()
        plan_json = parser.parse(response.content)
        print(f"--- ğŸ§  Planner æ–¹æ¡ˆå·²ç”Ÿæˆ ---")
        return {
            "plan": plan_json,
            "messages": [AIMessage(content=response.content)],
            "validation_error": None
        }
    except Exception as e:
        print(f"--- ğŸ›‘ Planner è¾“å‡º JSON è§£æå¤±è´¥: {e} ---")
        return {
            "plan": None,
            "validation_error": f"False, Planner è¾“å‡ºæ ¼å¼é”™è¯¯: {e}. è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¾“å‡ºã€‚",
            "messages": [AIMessage(content=response.content)]
        }

def plan_validator_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 2: Python éªŒè¯å™¨ """
    print("--- ğŸ è°ƒç”¨ Python éªŒè¯å™¨èŠ‚ç‚¹ ---")
    plan_json = state.get("plan")
    if plan_json is None:
        print("--- éªŒè¯å¤±è´¥: Planneræœªèƒ½ç”Ÿæˆæœ‰æ•ˆJSONã€‚---")
        return {"validation_error": state.get("validation_error", "False, Planner èŠ‚ç‚¹æœªèƒ½ç”Ÿæˆ JSONã€‚")}
    plan = plan_json.get("solution", {})
    if not plan:
        error = "False, æ–¹æ¡ˆ JSON ä¸¢å¤±æˆ–æ ¼å¼é”™è¯¯ï¼ˆæœªæ‰¾åˆ° 'solution' é”®ï¼‰ã€‚"
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    orientation = plan.get("orientation", "")
    site_type = plan.get("site_type", "")
    surf_atoms = plan.get("surface_binding_atoms", [])
    ads_atoms = plan.get("adsorbate_binding_atoms", [])
    if site_type == "ontop" and len(surf_atoms) != 1:
        error = f"False, Rule 1: Python check failed. site_type is 'ontop' but surface_binding_atoms has {len(surf_atoms)} members (should be 1)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if site_type == "bridge" and len(surf_atoms) != 2:
        error = f"False, Rule 1: Python check failed. site_type is 'bridge' but surface_binding_atoms has {len(surf_atoms)} members (should be 2)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if site_type == "hollow" and len(surf_atoms) < 3:
        error = f"False, Rule 1: Python check failed. site_type is 'hollow' but surface_binding_atoms has {len(surf_atoms)} members (should be >= 3)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if orientation == "end-on" and len(ads_atoms) != 1:
        error = f"False, Rule 2: Python check failed. orientation is 'end-on' but adsorbate_binding_atoms has {len(ads_atoms)} members (should be 1)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    if orientation == "side-on" and len(ads_atoms) < 2:
        error = f"False, Rule 2: Python check failed. orientation is 'side-on' but adsorbate_binding_atoms has {len(ads_atoms)} members (should be < 2)."
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        return {"validation_error": error}
    print("--- éªŒè¯æˆåŠŸ ---")
    return {"validation_error": None}


def smiles_translator_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 3: SMILES ç¿»è¯‘å™¨ """
    print("--- ğŸ”¬ è°ƒç”¨ SMILES ç¿»è¯‘å™¨èŠ‚ç‚¹ ---")
    try:
        plan = state["plan"]["solution"]
        original_smiles = state["smiles"]
        surrogate_smiles = generate_surrogate_smiles(
            original_smiles=original_smiles,
            binding_atoms=plan["adsorbate_binding_atoms"],
            orientation=plan["orientation"]
        )
        return {
            "surrogate_smiles": surrogate_smiles,
            "messages": [ToolMessage(content=f"SMILES ç¿»è¯‘æˆåŠŸ: {surrogate_smiles}", tool_call_id="smiles_translator")]
        }
    except Exception as e:
        print(f"--- ğŸ›‘ SMILES ç¿»è¯‘å¤±è´¥: {e} ---")
        return {
            "validation_error": f"False, SMILES ç¿»è¯‘å™¨å¤±è´¥: {e}. è¿™å¯èƒ½æ˜¯ä¸€ä¸ªæ— æ•ˆçš„é”®åˆæ–¹æ¡ˆï¼ˆä¾‹å¦‚ï¼Œåœ¨åˆ†å­ä¸­æœªæ‰¾åˆ° '{plan.get('adsorbate_binding_atoms', ['N/A'])[0]}'ï¼‰ã€‚è¯·é‡æ–°è§„åˆ’ã€‚",
            "messages": [ToolMessage(content=f"SMILES ç¿»è¯‘å¤±è´¥: {e}", tool_call_id="smiles_translator")]
        }

def tool_executor_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 4: Tool Executor """
    print("--- ğŸ› ï¸ è°ƒç”¨ Tool Executor èŠ‚ç‚¹ ---")
    plan = state["plan"]
    slab_path = state["slab_path"]
    surrogate_smiles = state["surrogate_smiles"]
    tool_logs = []
    analysis_json = None
    try:
        slab_atoms = read_atoms_object(slab_path)
        tool_logs.append(f"æˆåŠŸ: å·²ä» {slab_path} è¯»å– slab åŸå­ã€‚")
        fragment_atoms = get_fragment(SMILES=surrogate_smiles)
        if fragment_atoms is None:
            raise ValueError(f"RDKit failed to parse the surrogate_smiles: '{surrogate_smiles}'.")
        tool_logs.append(f"æˆåŠŸ: å·²ä» *SMILES '{surrogate_smiles}' ç”Ÿæˆç‰‡æ®µã€‚")
        site_df = get_sites_from_atoms(slab_atoms)
        if plan["solution"]["site_type"] == "ontop" and not site_df[site_df.connectivity == 1].empty:
             selected_site_dict = site_df[site_df.connectivity == 1].iloc[0].to_dict()
             tool_logs.append(f"æˆåŠŸ: å·²è¿‡æ»¤å¹¶é€‰æ‹©ç¬¬ä¸€ä¸ª 'ontop' ä½ç‚¹ã€‚")
        else:
            selected_site_dict = site_df.iloc[0].to_dict()
            tool_logs.append(f"æ³¨æ„: æœªæ‰¾åˆ°ç²¾ç¡® 'ontop' ä½ç‚¹ï¼Œå·²é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨ä½ç‚¹ã€‚")
        ads_slab_atoms = get_ads_slab(slab_atoms, fragment_atoms, selected_site_dict)
        tool_logs.append(f"æˆåŠŸ: å·²å°†ç‰‡æ®µæ”¾ç½®åœ¨ slab ä¸Šã€‚")
        print("--- â³ å¼€å§‹ç»“æ„å¼›è±«... ---")
        relaxed_atoms = relax_atoms(ads_slab_atoms, output_dir='./outputs')
        tool_logs.append(f"æˆåŠŸ: ç»“æ„å¼›è±«å®Œæˆã€‚å¼›è±«è½¨è¿¹ä¿å­˜åœ¨ './outputs/relax.traj'ã€‚")
        relaxed_xyz_path = './outputs/relaxed_ads_slab.xyz'
        save_ase_atoms(relaxed_atoms, relaxed_xyz_path)
        tool_logs.append(f"æˆåŠŸ: æœ€ç»ˆå¼›è±«ç»“æ„å·²ä¿å­˜åˆ° '{relaxed_xyz_path}'ã€‚")
        print("--- ğŸ”¬ è°ƒç”¨åˆ†æå·¥å…·... ---")
        analysis_json = analyze_relaxation_results(
            plan=plan,
            relaxed_xyz_path=relaxed_xyz_path,
            original_slab_path=slab_path
        )
        tool_logs.append(f"æˆåŠŸ: åˆ†æå·¥å…·å·²æ‰§è¡Œã€‚")
        print(f"--- ğŸ”¬ åˆ†æç»“æœ: {analysis_json} ---")
        print("--- âœ… å·¥å…·æ‰§è¡Œå®Œæ¯• ---")
    except Exception as e:
        print(f"--- ğŸ›‘ å·¥å…·æ‰§è¡Œå¤±è´¥: {e} ---")
        tool_logs.append(f"Error during tool execution: {str(e)}")
        analysis_json = json.dumps({"status": "error", "message": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"})
    return {
        "messages": [ToolMessage(content="\n".join(tool_logs), tool_call_id="executor_run")],
        "analysis_json": analysis_json
    }

def final_analysis_node(state: AgentState) -> dict:
    """ 
    èŠ‚ç‚¹ 5: Final Analyzer 
    æåº¦ä¸¥æ ¼çš„å¤±è´¥æç¤ºè¯ï¼Œé˜²æ­¢å¹»è§‰ã€‚
    """
    print("--- âœï¸ è°ƒç”¨ Final Analyzer èŠ‚ç‚¹ ---")
    llm = get_llm()
    analysis_data = {}
    try:
        analysis_json_str = state.get("analysis_json")
        if not analysis_json_str:
             analysis_data = {"status": "error", "message": "åˆ†æ JSON ä¸¢å¤±æˆ–ä¸ºç©ºã€‚"}
        else:
            analysis_data = json.loads(analysis_json_str)
    except json.JSONDecodeError:
        analysis_data = {"status": "error", "message": "Analysis JSON was corrupted."}
    
    if analysis_data.get("status") == "success":
        # æˆåŠŸè·¯å¾„ï¼šæˆ‘ä»¬æœ‰çœŸå®æ•°æ®
        final_prompt = """
        ä½ æ˜¯ä¸€åè®¡ç®—åŒ–å­¦ä¸“å®¶ã€‚
        ä½ çš„è§„åˆ’å’Œè®¡ç®—ä»»åŠ¡å·²æˆåŠŸæ‰§è¡Œï¼Œå¹¶ä¸”è‡ªåŠ¨åŒ–åˆ†æå·¥å…·å·²è¿”å›äº† *åŸºäºäº‹å®* çš„æ•°æ®ã€‚

        **ä½ çš„åŸå§‹è§„åˆ’ (ä½ å½“åˆçš„æ„å›¾):**
        {plan}

        **è‡ªåŠ¨åŒ–åˆ†æå·¥å…·è¿”å›çš„çœŸå®æ•°æ® (å®¢è§‚äº‹å®):**
        {analysis_json}

        **ä½ çš„ä»»åŠ¡:**
        1.  **è§£è¯»æ•°æ®:** æŸ¥çœ‹ `analysis_json`ã€‚`is_covalently_bound` æ˜¯ True è¿˜æ˜¯ Falseï¼Ÿ`final_bond_distance_A` æ˜¯å¤šå°‘ï¼Ÿ
        2.  **å›ç­”è¯·æ±‚:** æ ¹æ®è¿™ä¸ª *çœŸå®æ•°æ®*ï¼ˆè€Œä¸æ˜¯çŒœæµ‹ï¼‰ï¼Œå›ç­”ç”¨æˆ·çš„åŸå§‹è¯·æ±‚ï¼š
            '{user_request}'
        3.  **ç¦æ­¢å¹»è§‰:** ä½ çš„æŠ¥å‘Šå¿…é¡» 100% å»ºç«‹åœ¨ä¸Šè¿° JSON æ•°æ®çš„å®¢è§‚äº‹å®ä¸Šã€‚
        """
        plan_str = json.dumps(state.get("plan", "{}"))
        prompt = final_prompt.format(
            plan=plan_str, 
            analysis_json=state["analysis_json"], 
            user_request=state["user_request"]
        )
    
    else:
        # å¤±è´¥è·¯å¾„ - ä¸¥æ ¼ç¦æ­¢å¹»è§‰
        final_prompt = """
        ä½ æ˜¯ä¸€ä¸ªé”™è¯¯æŠ¥å‘ŠåŠ©æ‰‹ã€‚
        è®¡ç®—ä»»åŠ¡æ‰§è¡Œå¤±è´¥äº†ã€‚

        **ä½ çš„å”¯ä¸€ä»»åŠ¡:**
        1.  ç¤¼è²Œåœ°å‘ŠçŸ¥ç”¨æˆ·è®¡ç®—æ¨¡æ‹Ÿå¤±è´¥ã€‚
        2.  **é€å­—** æŠ¥å‘Š `analysis_json` ä¸­çš„ "message" å­—æ®µã€‚
        3.  **ä¸¥æ ¼ç¦æ­¢** å°è¯•å›ç­”ç”¨æˆ·çš„åŸå§‹ç§‘å­¦é—®é¢˜ã€‚
        4.  **ä¸¥æ ¼ç¦æ­¢** çŒœæµ‹å¤±è´¥çš„åŸå› æˆ–æä¾›ä»»ä½•ç§‘å­¦å»ºè®®ã€‚
        
        **å·¥å…·æ‰§è¡Œé”™è¯¯æ—¥å¿— (å¿…é¡»æŠ¥å‘Š):**
        {analysis_json}
        
        **ç¤ºä¾‹è¾“å‡º:**
        "æŠ±æ­‰ï¼Œè®¡ç®—æ¨¡æ‹Ÿæ‰§è¡Œå¤±è´¥ã€‚è‡ªåŠ¨åŒ–å·¥å…·æŠ¥å‘Šäº†ä»¥ä¸‹é”™è¯¯ï¼š<analysis_json["message"]>"
        """
        prompt = final_prompt.format(
            analysis_json=state.get("analysis_json", '{"status": "error", "message": "æœªçŸ¥çš„åˆ†æé”™è¯¯ã€‚"}')
            # ç§»é™¤äº† {user_request} æ¥é˜²æ­¢å¹»è§‰
        )
    
    response = llm.invoke([HumanMessage(content=prompt)])
    
    print("--- ğŸ æµç¨‹ç»“æŸ ---")
    return {"messages": [AIMessage(content=response.content)]}

# --- 4. å®šä¹‰å›¾çš„é€»è¾‘æµ (Edges) ---
def route_after_validation(state: AgentState) -> str:
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 1 (éªŒè¯å™¨) ---")
    if state.get("validation_error"):
        print(f"--- å†³ç­–: æ–¹æ¡ˆå¤±è´¥ï¼Œè¿”å›è§„åˆ’ ---")
        return "planner"
    else:
        print(f"--- å†³ç­–: æ–¹æ¡ˆé€šè¿‡ï¼Œå‰å¾€ç¿»è¯‘ ---")
        return "smiles_translator"

def route_after_translation(state: AgentState) -> str:
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 2 (ç¿»è¯‘å™¨) ---")
    if state.get("validation_error"):
        print(f"--- å†³ç­–: ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›è§„åˆ’ ---")
        return "planner"
    else:
        print(f"--- å†³ç­–: ç¿»è¯‘æˆåŠŸï¼Œå‰å¾€æ‰§è¡Œ ---")
        return "tool_executor"

# --- 5. æ„å»ºå¹¶ç¼–è¯‘å›¾ (Graph) ---
def get_agent_executor():
    """ æ„å»ºå¹¶ç¼–è¯‘ Adsorb-Agent çŠ¶æ€æœºå›¾ã€‚"""
    workflow = StateGraph(AgentState)
    workflow.add_node("planner", solution_planner_node)
    workflow.add_node("plan_validator", plan_validator_node) 
    workflow.add_node("smiles_translator", smiles_translator_node)
    workflow.add_node("tool_executor", tool_executor_node)
    workflow.add_node("final_analyzer", final_analysis_node)
    workflow.set_entry_point("planner")
    workflow.add_edge("planner", "plan_validator")
    workflow.add_edge("tool_executor", "final_analyzer")
    workflow.add_edge("final_analyzer", END)
    workflow.add_conditional_edges(
        "plan_validator",
        route_after_validation,
        {"smiles_translator": "smiles_translator", "planner": "planner"}
    )
    workflow.add_conditional_edges(
        "smiles_translator",
        route_after_translation,
        {"tool_executor": "tool_executor", "planner": "planner"}
    )
    return workflow.compile()

# --- 6. è¿è¡Œç¨‹åº ---
def _prepare_initial_state(smiles: str, slab_path: str, user_request: str) -> AgentState:
    return {
        "smiles": smiles,
        "slab_path": slab_path,
        "user_request": user_request,
        "plan": None,
        "validation_error": None,
        "messages": [HumanMessage(content=f"SMILES: {smiles}\nSLAB: {slab_path}\nREQUEST: {user_request}")],
        "analysis_json": None,
        "surrogate_smiles": None
    }

def parse_args():
    parser = argparse.ArgumentParser(description="Run the Adsorb-Agent.")
    parser.add_argument("--smiles", type=str, required=True, help="SMILES string.")
    parser.add_argument("--slab_path", type=str, required=True, help="Path to the slab .xyz file.")
    parser.add_argument("--user_request", type=str, default="Find a stable adsorption configuration.", help="User's request.")
    return parser.parse_args()

# @weave.op()
def main_cli():
    args = parse_args()
    if not os.path.exists('./outputs'):
        os.makedirs('./outputs')
    initial_state = _prepare_initial_state(args.smiles, args.slab_path, args.user_request)
    agent_executor = get_agent_executor()
    print("\n--- ğŸš€ Adsorb-Agent å·²å¯åŠ¨ ---\n")
    final_state = None
    for chunk in agent_executor.stream(initial_state, stream_mode="values"):
        final_state = chunk
        if "messages" in final_state and final_state["messages"]:
            last_message = final_state["messages"][-1]
            if isinstance(last_message, (AIMessage, ToolMessage)):
                print("\n---")
                print(f"[{last_message.type}]")
                print(last_message.content)
                print("---\n")
    print("\n--- ğŸ Adsorb-Agent ä»»åŠ¡å®Œæˆ ---\n")
    print("æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
    if final_state and "messages" in final_state:
        print(final_state["messages"][-1].content)

if __name__ == '__main__':
    exec_globals = builtins.__dict__.copy()
    exec_globals.update({
        "np": np, "pd": pd, "scipy": scipy, "sklearn": sklearn, "math": math,
        "ase": ase, "autoadsorbate": autoadsorbate, "torch": torch, "mace": mace,
    })
    
    main_cli()