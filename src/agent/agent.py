import os
import builtins
import math
import argparse
import json
from collections import Counter
from typing import TypedDict, List, Optional
import numpy as np
import pandas as pd
import scipy
import sklearn
from rdkit import Chem
import ase
from  ase.io import read
import autoadsorbate
import torch
import mace
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage
from langgraph.graph import StateGraph, END
from langchain_core.output_parsers import JsonOutputParser

from src.tools.tools import (
    read_atoms_object,
    get_atom_index_menu,
    prepare_slab,
    analyze_surface_sites,
    create_fragment_from_plan,
    populate_surface_with_fragment,
    relax_atoms, 
    save_ase_atoms,
    analyze_relaxation_results
)
from src.agent.prompts import PLANNER_PROMPT

MAX_RETRIES = 5

# --- 1. å®šä¹‰æ™ºèƒ½ä½“çŠ¶æ€ (Agent State) ---
class AgentState(TypedDict):
    smiles: str
    slab_path: str
    surface_composition: Optional[List[str]]
    user_request: str
    plan: Optional[dict]
    validation_error: Optional[str]
    messages: List[BaseMessage]
    analysis_json: Optional[str]
    history: List[str]
    best_result: Optional[dict]
    best_dissociated_result: Optional[dict]
    attempted_keys: List[str]
    available_sites_description: Optional[str]

# --- 2. è®¾ç½®ç¯å¢ƒå’Œ LLM ---
load_dotenv()

if not os.environ.get("GOOGLE_API_KEY"):
    raise ValueError("GOOGLE_API_KEY environment variable not set.")
# if not os.environ.get("OPENROUTER_API_KEY"):
#     raise ValueError("OPENROUTER_API_KEY environment variable not set.")

def get_llm():
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", 
        temperature=0.0, 
        max_tokens=4096, 
        timeout=120, 
    )
    # llm = ChatOpenAI(
    #     openai_api_base="https://openrouter.ai/api/v1",
    #     openai_api_key=os.getenv("OPENROUTER_API_KEY"),
    #     model="google/gemini-2.5-pro",
    #     streaming=False, 
    #     temperature=0.0,
    #     max_tokens=4096, 
    #     timeout=120, 
    #     seed=42
    # )
    return llm

def make_plan_key(plan_json: Optional[dict]) -> Optional[str]:
    if not plan_json or not isinstance(plan_json, dict):
        return None
    try:
        solution = plan_json.get("solution", {}) or {}
        site_type = solution.get("site_type", "") or ""
        surf_atoms = solution.get("surface_binding_atoms", []) or []
        ads_indices = solution.get("adsorbate_binding_indices", []) or []
        touch_sphere = solution.get("touch_sphere_size", 3)
        ads_type = plan_json.get("adsorbate_type", "Molecule")

        # ç¡®ä¿ä¸¤è€…æ˜¯ listï¼Œå¦åˆ™è¿”å› Noneï¼ˆä¸æŠ›å¼‚å¸¸ï¼‰
        if not isinstance(surf_atoms, list) or not isinstance(ads_indices, list):
            return None

        # ç»Ÿä¸€è½¬æˆå­—ç¬¦ä¸²ï¼Œä¿ç•™é¡ºåºä»¥åŒºåˆ†å¼‚æ ¸åŒç‚¹å¸é™„çš„æ–¹å‘ (å¦‚ Mo-Pd vs Pd-Mo)
        surf_atoms_str = ",".join(str(s) for s in surf_atoms)
        ads_indices_str = ",".join(str(i) for i in ads_indices)

        key = f"{site_type}|{surf_atoms_str}|{ads_indices_str}|{ads_type}|{touch_sphere}"
        return key
    except Exception as e:
        print(f"--- âš ï¸ make_plan_key å¤±è´¥: {e} ---")
        return None

# --- 3. å®šä¹‰ LangGraph èŠ‚ç‚¹ ---
def pre_processor_node(state: AgentState) -> dict:
    print("--- ğŸ”¬ è°ƒç”¨ Pre-Processor èŠ‚ç‚¹ ---")
    try:
        analysis = analyze_surface_sites(state["slab_path"])
        return {
            "surface_composition": analysis["surface_composition"],
            "available_sites_description": analysis["available_sites_description"]
        }
    except Exception as e:
        error_message = f"é”™è¯¯: æ— æ³•è¯»å– Slab æ–‡ä»¶ '{state['slab_path']}': {e}"
        print(f"--- éªŒè¯å¤±è´¥: {error_message} ---")
        return {
            "validation_error": error_message,
            "surface_composition": None,
            "available_sites_description": None
        }

def solution_planner_node(state: AgentState) -> dict:
    print("--- ğŸ§  è°ƒç”¨ Planner èŠ‚ç‚¹ ---")
    llm = get_llm()
    messages = []

    try:
        atom_menu_json = get_atom_index_menu(state["smiles"])
        if "error" in atom_menu_json:
            raise ValueError(atom_menu_json)
    except Exception as e:
        print(f"--- ğŸ›‘ fatal error: Unable to generate atom menu for SMILES {state['smiles']}: {e} ---")
        return {
            "validation_error": f"False, fatal error: Unable to generate atom menu for SMILES {state['smiles']}: {e}"
        }
    
    prompt_input = {
        "smiles": state["smiles"],
        "slab_xyz_path": state["slab_path"],
        "surface_composition": state.get("surface_composition", "æœªçŸ¥"),
        "user_request": state["user_request"],
        "history": "\n".join(state["history"]) if state.get("history") else "æ— ",
        "MAX_RETRIES": MAX_RETRIES,
        "autoadsorbate_context": atom_menu_json,
        "available_sites_description": state.get("available_sites_description", "æ— "),
    }
    
    if state.get("validation_error"):
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))
        messages.append(AIMessage(content=json.dumps(state.get("plan", "{}"))))
        messages.append(HumanMessage(content=f"ä½ çš„æ–¹æ¡ˆå­˜åœ¨é€»è¾‘é”™è¯¯: {state['validation_error']}. è¯·é‡æ–°è§„åˆ’ä¸€ä¸ªæ–°æ–¹æ¡ˆã€‚"))
    else:
        if state.get("history"):
            print(f"--- ğŸ§  Planner: æ£€æµ‹åˆ°å¤±è´¥å†å²ï¼Œæ­£åœ¨é‡è¯•... ---")
        messages.append(HumanMessage(content=PLANNER_PROMPT.format(**prompt_input)))

    response = llm.invoke(messages)
    
    try:
        parser = JsonOutputParser()

        content_str = response.content
        if content_str.startswith("```json"):
            content_str = content_str[7:-3].strip()
        
        plan_json = parser.parse(content_str)
        print(f"--- ğŸ§  Planner æ–¹æ¡ˆå·²ç”Ÿæˆ ---")
        return {
            "plan": plan_json,
            "messages": [AIMessage(content=response.content)],
            "validation_error": None
        }
    except Exception as e:
        print(f"--- ğŸ›‘ Planner è¾“å‡º JSON è§£æå¤±è´¥: {e} ---")
        print(f"--- åŸå§‹è¾“å‡º: {response.content} ---")
        return {
            "plan": None,
            "validation_error": f"False, Planner è¾“å‡ºæ ¼å¼é”™è¯¯: {e}. è¯·ä¸¥æ ¼æŒ‰ JSON æ ¼å¼è¾“å‡ºã€‚",
            "messages": [AIMessage(content=response.content)]
        }

def plan_validator_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 2: Python éªŒè¯å™¨ """
    print("--- ğŸ è°ƒç”¨ Python éªŒè¯å™¨èŠ‚ç‚¹ ---")

    try:
        # ä½¿ç”¨ state["smiles"] (æ¥è‡ªåˆå§‹è¾“å…¥) è€Œä¸æ˜¯ plan ä¸­çš„ä»»ä½•å†…å®¹
        mol = Chem.MolFromSmiles(state["smiles"])
        if not mol:
            raise ValueError(f"RDKit è¿”å› Noneã€‚SMILES å¯èƒ½æ— æ•ˆæˆ–åŒ…å« RDKit æ— æ³•å¤„ç†çš„ä»·æ€ã€‚")
    except Exception as e:
        error = f"False, åŸºç¡€ SMILES å­—ç¬¦ä¸² '{state['smiles']}' æ— æ³•è¢« RDKit è§£æã€‚è¿™æ˜¯ä¸€ä¸ªæ— æ³•ä¿®å¤çš„é”™è¯¯ã€‚è¯·æ£€æŸ¥ SMLIESã€‚é”™è¯¯: {e}"
        print(f"--- éªŒè¯å¤±è´¥: {error} ---")
        # è¿™æ˜¯ä¸€ä¸ªè‡´å‘½é”™è¯¯ï¼›æˆ‘ä»¬åº”è¯¥åœæ­¢é‡è¯•ã€‚
        # æˆ‘ä»¬é€šè¿‡è®¾ç½®ä¸€ä¸ªç‰¹æ®Šçš„ validation_error æ¥é€šçŸ¥è·¯ç”±
        # æ³¨æ„ï¼šç†æƒ³æƒ…å†µä¸‹ï¼Œå›¾åº”è¯¥æœ‰ä¸€ä¸ª "terminal_failure" çŠ¶æ€ï¼Œ
        # ä½†ç›®å‰æˆ‘ä»¬åªèƒ½è¿”å›ç»™ plannerï¼Œå¹¶æœŸæœ›å®ƒåœ¨ N æ¬¡ååœæ­¢ã€‚
        return {"validation_error": error, "plan": None} # æ¸…é™¤ plan

    plan_json = state.get("plan")
    if plan_json is None:
        print("--- Validation Failed: Planner failed to generate valid JSON. ---")
        return {"validation_error": state.get("validation_error", "False, Planner node failed to generate valid JSON.")}
    if "solution" not in plan_json:
        error = "False, Plan JSON missing 'solution' key."
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    
    adsorbate_type = plan_json.get("adsorbate_type")
    if adsorbate_type not in ["Molecule", "ReactiveSpecies"]:
        error = f"False, Plan JSON missing or invalid `adsorbate_type` field (must be 'Molecule' or 'ReactiveSpecies')."
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}

    solution = plan_json.get("solution", {})
    if not solution:
        error = "False, Plan JSON missing or malformed ('solution' key is empty)."
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if solution.get("action") == "terminate":
        print("--- ğŸ›‘ Planner å†³å®šä¸»åŠ¨ç»ˆæ­¢ä»»åŠ¡ (æ”¶æ•›æˆ–æ— æ›´å¤šæ–¹æ¡ˆ) ---")
        return {"validation_error": None}  # ç›´æ¥é€šè¿‡ï¼Œä¸å†æ£€æŸ¥ site_type ç­‰ç»†èŠ‚

    site_type = solution.get("site_type", "")
    surf_atoms = solution.get("surface_binding_atoms", [])
    ads_indices = solution.get("adsorbate_binding_indices", [])
    if site_type == "ontop" and len(ads_indices) != 1:
        error = f"False, Rule 2: Python check failed. site_type 'ontop' å¿…é¡»ä¸ 1 ä¸ªç´¢å¼• (end-on) é…å¯¹ï¼Œä½†æä¾›äº† {len(ads_indices)} ä¸ªã€‚"
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if site_type == "bridge" and len(ads_indices) not in [1, 2]:
        error = f"False, Rule 2: Python check failed. site_type 'bridge' å¿…é¡»ä¸ 1 ä¸ª (end-on) æˆ– 2 ä¸ª (side-on) ç´¢å¼•é…å¯¹ï¼Œä½†æä¾›äº† {len(ads_indices)} ä¸ªã€‚"
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if site_type == "hollow" and len(ads_indices) not in [1, 2]:
        error = f"False, Rule 2: Python check failed. site_type 'hollow' å¿…é¡»ä¸ 1 ä¸ª (end-on) æˆ– 2 ä¸ª (side-on) ç´¢å¼•é…å¯¹ï¼Œä½†æä¾›äº† {len(ads_indices)} ä¸ªã€‚"
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if not isinstance(surf_atoms, list):
        error = "False, Plan JSON field 'surface_binding_atoms' å¿…é¡»æ˜¯åˆ—è¡¨ã€‚"
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if site_type == "ontop" and len(surf_atoms) != 1:
        error = (
            "False, Rule 2b: 'ontop' ä½ç‚¹è¦æ±‚ surface_binding_atoms é•¿åº¦ä¸º 1ï¼Œ"
            f"ä½†å½“å‰ä¸º {len(surf_atoms)}ã€‚"
        )
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if site_type == "bridge" and len(surf_atoms) not in [1, 2]:
        error = (
            "False, Rule 2b: 'bridge' ä½ç‚¹è¦æ±‚ surface_binding_atoms é•¿åº¦ä¸º 1 æˆ– 2ï¼Œ"
            f"ä½†å½“å‰ä¸º {len(surf_atoms)}ã€‚"
        )
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    if site_type == "hollow" and len(surf_atoms) < 3:
        error = (
            "False, Rule 2b: 'hollow' ä½ç‚¹è¦æ±‚ surface_binding_atoms è‡³å°‘åŒ…å« 3 ä¸ªå…ƒç´ ï¼Œ"
            f"ä½†å½“å‰ä¸º {len(surf_atoms)}ã€‚"
        )
        print(f"--- Validation Failed: {error} ---")
        return {"validation_error": error}
    
    try:
        attempted_keys = state.get("attempted_keys", [])
        if not isinstance(attempted_keys, list):
            attempted_keys = []
        key = make_plan_key(plan_json)
        if key is not None and key in attempted_keys:
            error = (
                "False, è¯¥æ–¹æ¡ˆåœ¨ (site_type, surface_binding_atoms, adsorbate_binding_indices) "
                "ç©ºé—´ä¸­å·²ç»å°è¯•è¿‡ï¼Œè¯·è§„åˆ’ä¸€ä¸ªä¸åŒçš„ç»„åˆã€‚"
            )
            print(f"--- Validation Failed: {error} ---")
            return {"validation_error": error}
    except Exception as e_dup:
        print(f"--- âš ï¸ Duplicate-check è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e_dup} ---")

    print("--- Validation Succeeded ---")
    return {"validation_error": None}

def tool_executor_node(state: AgentState) -> dict:
    """ èŠ‚ç‚¹ 4: Tool Executor """
    print("--- ğŸ› ï¸ è°ƒç”¨ Tool Executor èŠ‚ç‚¹ ---")
    
    plan_json = state.get("plan", {})
    plan_solution = plan_json.get("solution", {})

    if not plan_solution:
        error_message = "Tool Executor å¤±è´¥: 'plan' ä¸­ç¼ºå°‘ 'solution' å­—å…¸ã€‚"
        print(f"--- ğŸ›‘ {error_message} ---")
        return {
            "messages": [ToolMessage(content=error_message, tool_call_id="tool_executor")],
            "analysis_json": json.dumps({"status": "error", "message": error_message})
        }

    slab_path = state["slab_path"]
    tool_logs = []
    analysis_json = None

    new_best_molecular = state.get("best_result")
    new_best_dissociated = state.get("best_dissociated_result")
    
    try:
        # 1. è¯»å–åŸå§‹ Slab
        raw_slab_atoms = read_atoms_object(slab_path)
        tool_logs.append(f"æˆåŠŸ: å·²ä» {slab_path} è¯»å– slab åŸå­ã€‚")

        # 2. åœ¨è®¡ç®—ä»»ä½•èƒ½é‡ä¹‹å‰ï¼Œå…ˆç»Ÿä¸€å¤„ç† Slab
        final_slab_atoms, is_expanded = prepare_slab(raw_slab_atoms)
        if is_expanded:
            tool_logs.append("æ³¨æ„: ä¸ºäº†ç‰©ç†å‡†ç¡®æ€§ï¼ŒSlab å·²è¢«è‡ªåŠ¨æ‰©èƒ (2x2)ã€‚")
        
        # 3. åˆå§‹åŒ–è®¡ç®—å™¨
        try:
            import torch
            from ase import units
            from ase.constraints import FixAtoms
            from ase.md.langevin import Langevin
            from ase.md.velocitydistribution import MaxwellBoltzmannDistribution
            from ase.optimize import BFGS
            from mace.calculators import mace_mp
            
            # ç»Ÿä¸€å®šä¹‰å¼›è±«å‚æ•°
            opt_fmax = 0.05
            opt_steps = 500
            md_steps = 20
            md_temp = 150.0
            mace_model = "small"
            mace_device = "cuda" if torch.cuda.is_available() else "cpu"
            
            temp_calc = mace_mp(model=mace_model, device=mace_device, default_dtype='float32', dispersion=True)

        except Exception as e_calc:
            raise ValueError(f"Failed to initialize MACE calculator: {e_calc}")

        # 4. è®¡ç®— E_surface
        try:
            e_surf_atoms = final_slab_atoms.copy()
            e_surf_atoms.calc = temp_calc

            # *** åº”ç”¨ä¸ relax_atoms *å®Œå…¨ä¸€è‡´* çš„çº¦æŸ ***
            # tools.py::relax_atoms å›ºå®šäº† *æ‰€æœ‰* è¡¨é¢åŸå­ã€‚
            constraint = FixAtoms(indices=list(range(len(e_surf_atoms))))
            e_surf_atoms.set_constraint(constraint)

            print(f"--- ğŸ› ï¸ æ­£åœ¨è®¡ç®—è£¸è¡¨é¢çš„å•ç‚¹èƒ½ (æ‰€æœ‰åŸå­å·²å›ºå®š)... ---")

            E_surface = e_surf_atoms.get_potential_energy() # è¿™ç°åœ¨æ˜¯ä¸€ä¸ªå•ç‚¹èƒ½
            tool_logs.append(f"Success: E_surface = {E_surface:.4f} eVã€‚")
            
        except Exception as e_surf_err:
            raise ValueError(f"Failed to calculate E_surface: {e_surf_err}")

        # 5. åˆ›å»º Fragment
        fragment_object = create_fragment_from_plan(
            original_smiles=state["smiles"],
            binding_atom_indices=plan_solution.get("adsorbate_binding_indices"),
            plan_dict=plan_json,
            to_initialize=plan_solution.get("conformers_per_site_cap", 5)
        )
        tool_logs.append(f"Success: Created fragment object from plan (SMILES: {state['smiles']}).")

        # 6. è®¡ç®— E_adsorbate
        try:
            adsorbate_only_atoms = fragment_object.conformers[0].copy()
            
            # ç§»é™¤æ ‡è®°
            if adsorbate_only_atoms.info["smiles"] == "Cl":
                del adsorbate_only_atoms[0]
            elif adsorbate_only_atoms.info["smiles"] == "S1S":
                del adsorbate_only_atoms[:2]
                
            adsorbate_only_atoms.calc = temp_calc
            adsorbate_only_atoms.set_cell([20, 20, 20]) 
            adsorbate_only_atoms.center()
            
            print(f"--- ğŸ› ï¸ æ­£åœ¨å¼›è±«å­¤ç«‹çš„ {state['smiles']} åˆ†å­... ---")

            # æ£€æµ‹å•åŸå­åˆ†å­ã€‚å•åŸå­åœ¨çœŸç©ºä¸­æ²¡æœ‰å†…éƒ¨è‡ªç”±åº¦ï¼ŒåŠ¿èƒ½é¢å¹³å¦ï¼Œå¯¼è‡´ BFGS ç®—æ³•å› åŠ›å˜åŒ–ä¸º0è€Œé™¤ä»¥é›¶å´©æºƒã€‚
            if len(adsorbate_only_atoms) > 1:
                # åè®® 1: MD é¢„çƒ­ (ä¸ relax_atoms ä¸€è‡´)
                if md_steps > 0:
                    MaxwellBoltzmannDistribution(adsorbate_only_atoms, temperature_K=md_temp)
                    dyn_md_ads = Langevin(adsorbate_only_atoms, 1 * units.fs, temperature_K=md_temp, friction=0.01)
                    dyn_md_ads.run(md_steps)
                    
                # åè®® 2: BFGS ä¼˜åŒ– (ä¸ relax_atoms ä¸€è‡´)
                BFGS(adsorbate_only_atoms, trajectory=None, logfile=None).run(fmax=opt_fmax, steps=opt_steps)
            else:
                print(f"--- ğŸ› ï¸ æ£€æµ‹åˆ°å•åŸå­å¸é™„ç‰© ({len(adsorbate_only_atoms)} atom)ï¼Œè·³è¿‡çœŸç©ºå¼›è±«ï¼ˆç‰©ç†ä¸Šæ— éœ€ä¼˜åŒ–ï¼‰ã€‚ ---")
            
            E_adsorbate = adsorbate_only_atoms.get_potential_energy()
            tool_logs.append(f"Success: E_adsorbate = {E_adsorbate:.4f} eV.")
            
        except Exception as e_ads_err:
            raise ValueError(f"è®¡ç®— E_adsorbate å¤±è´¥: {e_ads_err}")

        # 7. æ”¾ç½®å¸é™„ç‰©
        generated_traj_file = populate_surface_with_fragment(
            slab_atoms=final_slab_atoms,
            fragment_object=fragment_object,
            plan_solution=plan_solution
        )
        tool_logs.append(f"æˆåŠŸ: å·²å°†ç‰‡æ®µæ”¾ç½®åœ¨ slab ä¸Šã€‚æ„å‹ä¿å­˜åœ¨: {generated_traj_file}")

        initial_conformers = read(generated_traj_file, index=":")
        if not initial_conformers or len(initial_conformers) == 0:
            raise ValueError(f"populate_surface_with_fragment æœªèƒ½ç”Ÿæˆä»»ä½•æ„å‹ (è½¨è¿¹æ–‡ä»¶ä¸ºç©º: {generated_traj_file})ã€‚")
        
        # 8. ç»“æ„å¼›è±«
        print("--- â³ å¼€å§‹ç»“æ„å¼›è±«... ---")
        slab_indices = list(range(len(final_slab_atoms)))
        relax_n = plan_solution.get("relax_top_n", 1)
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"--- ğŸ› ï¸ MACE å°†ä½¿ç”¨è®¾å¤‡: {device} ---")

        final_traj_file = relax_atoms(
            atoms_list=list(initial_conformers),
            slab_indices=slab_indices,
            relax_top_n=relax_n,
            fmax=opt_fmax,
            steps=opt_steps,
            md_steps=md_steps,
            md_temp=md_temp,
            mace_model=mace_model,
            mace_device=mace_device
        )
        tool_logs.append(f"æˆåŠŸ: ç»“æ„å¼›è±«å®Œæˆ (å¼›è±«äº† Top {relax_n})ã€‚è½¨è¿¹ä¿å­˜åœ¨ '{final_traj_file}'ã€‚")
        
        # 9. åˆ†æç»“æœ
        print("--- ğŸ”¬ è°ƒç”¨åˆ†æå·¥å…·... ---")
        analysis_json_str = analyze_relaxation_results(
            relaxed_trajectory_file=final_traj_file,
            slab_atoms=final_slab_atoms,
            original_smiles=state["smiles"],
            plan_dict=plan_json,
            e_surface_ref=E_surface,
            e_adsorbate_ref=E_adsorbate
        )
        tool_logs.append(f"æˆåŠŸ: åˆ†æå·¥å…·å·²æ‰§è¡Œã€‚")
        print(f"--- ğŸ”¬ åˆ†æç»“æœ: {analysis_json_str} ---")
        analysis_json = json.loads(analysis_json_str)

        if analysis_json.get("status") == "success":
            e_new = analysis_json.get("most_stable_energy_eV")
            is_dissociated = analysis_json.get("is_dissociated")

            # é€»è¾‘åˆ†æ”¯ A: å¦‚æœæ˜¯å®Œæ•´çš„åˆ†å­ (Molecular State)
            if not is_dissociated:
                e_old_mol = new_best_molecular.get("most_stable_energy_eV", float('inf')) if new_best_molecular else float('inf')
                if isinstance(e_new, (int, float)) and e_new < e_old_mol:
                    print(f"--- ğŸŒŸ å‘ç°æ–°æœ€ä¼˜ [åˆ†å­æ€]: {e_new:.4f} eV ---")
                    new_best_molecular = {
                        "most_stable_energy_eV": e_new,
                        "analysis_json": analysis_json,
                        "plan": state.get("plan"),
                        "result_type": "Perfect" if analysis_json.get("bond_change_count")==0 else "Isomerized"
                    }

            # é€»è¾‘åˆ†æ”¯ B: å¦‚æœæ˜¯è§£ç¦»æ€ (Dissociated State) - [æ–°å¢]
            else:
                e_old_diss = new_best_dissociated.get("most_stable_energy_eV", float('inf')) if new_best_dissociated else float('inf')
                if isinstance(e_new, (int, float)) and e_new < e_old_diss:
                    print(f"--- âš ï¸ å‘ç°æ›´ç¨³å®šçš„ [è§£ç¦»æ€]: {e_new:.4f} eV (å°†ä½œä¸ºçƒ­åŠ›å­¦å‚è€ƒ) ---")
                    new_best_dissociated = {
                        "most_stable_energy_eV": e_new,
                        "analysis_json": analysis_json,
                        "plan": state.get("plan"),
                        "result_type": "Dissociated"
                    }

    except Exception as e:
        error_message = str(e)
        print(f"--- ğŸ›‘ å·¥å…·æ‰§è¡Œå¤±è´¥: {error_message} ---")
        tool_logs.append(f"Error during tool execution: {error_message}")
        analysis_json = {"status": "error", "message": f"å·¥å…·æ‰§è¡Œå¤±è´¥: {error_message}"}
        
    return {
        "messages": [ToolMessage(content="\n".join(tool_logs), tool_call_id="tool_executor")],
        "analysis_json": json.dumps(analysis_json),
        "best_result": new_best_molecular,
        "best_dissociated_result": new_best_dissociated
    }

def final_analyzer_node(state: AgentState) -> dict:
    """ 
    èŠ‚ç‚¹ 5: Final Analyzer
    åŠŸèƒ½ï¼šåŸºäºå…¨å±€æœ€ä¼˜ç»“æœç”ŸæˆæŠ¥å‘Šï¼Œå¹¶åŒºåˆ†å®Œç¾å¸é™„ä¸åˆ†å­å†…é‡æ’ã€‚
    """
    print("--- âœï¸ è°ƒç”¨ Final Analyzer èŠ‚ç‚¹ ---")
    llm = get_llm()
    
    # 1. æå–æ•°æ®æº
    best_result = state.get("best_result")
    best_dissociated = state.get("best_dissociated_result")
    last_analysis_json_str = state.get("analysis_json", "{}")
    
    try:
        last_analysis = json.loads(last_analysis_json_str)
    except:
        last_analysis = {}

    # 2. å†³ç­–ï¼šæ±‡æŠ¥å“ªä¸ªæ•°æ®ï¼Ÿ
    target_data = None
    plan_used = None
    source_type = "failure"
    result_label = "Unknown" # ç”¨äºæç¤º LLM ç»“æœç±»å‹

    # ä¼˜å…ˆçº§ 1: å†å²æœ€ä¼˜
    if best_result and isinstance(best_result, dict):
        print(f"--- âœï¸ Final Analyzer: é”å®šå…¨å±€æœ€ä¼˜æ–¹æ¡ˆ (E={best_result.get('most_stable_energy_eV')} eV) ---")
        target_data = best_result.get("analysis_json")
        plan_used = best_result.get("plan")
        # å¦‚æœ route_after_analysis ä¿å­˜äº† result_typeï¼Œåˆ™è¯»å–å®ƒ
        result_label = best_result.get("result_type", "Best History")
        source_type = "success"
    
    # ä¼˜å…ˆçº§ 2: æœ€åä¸€æ¬¡å°è¯•æˆåŠŸ
    elif last_analysis.get("status") == "success" and last_analysis.get("is_covalently_bound"):
        print("--- âœï¸ Final Analyzer: æ— å†å²æœ€ä¼˜ï¼Œä½¿ç”¨æœ€åä¸€æ­¥çš„æˆåŠŸç»“æœ ---")
        target_data = last_analysis
        plan_used = state.get("plan")
        result_label = "Last Attempt"
        source_type = "success"
    
    else:
        print("--- âœï¸ Final Analyzer: æ‰€æœ‰å°è¯•å‡å¤±è´¥ ---")
        source_type = "failure"

    # 3. æ„å»º Prompt
    if source_type == "success":
        data_str = json.dumps(target_data, indent=2, ensure_ascii=False)
        plan_str = json.dumps(plan_used, indent=2, ensure_ascii=False)
        
        # [æ–°å¢] å‡†å¤‡è§£ç¦»æ€å¯¹æ¯”æ•°æ®
        diss_warning_context = ""
        if best_dissociated:
            e_mol = target_data.get("most_stable_energy_eV", 999)
            e_diss = best_dissociated.get("most_stable_energy_eV", 999)
            if e_diss < e_mol:
                delta_E = e_diss - e_mol
                diss_warning_context = (
                    f"\n*** ä¸¥é‡çƒ­åŠ›å­¦è­¦å‘Šæ•°æ® ***\n"
                    f"è™½ç„¶ç”¨æˆ·è¦æ±‚å¯»æ‰¾åˆ†å­å¸é™„ï¼Œä½†ç³»ç»Ÿåœ¨å†å²è®¡ç®—ä¸­å‘ç°äº†èƒ½é‡æ›´ä½çš„è§£ç¦»æ€ã€‚\n"
                    f"- åˆ†å­æ€èƒ½é‡: {e_mol:.3f} eV\n"
                    f"- è§£ç¦»æ€èƒ½é‡: {e_diss:.3f} eV (æ›´ç¨³å®š {abs(delta_E):.3f} eV)\n"
                    f"è¿™æ„å‘³ç€æŠ¥å‘Šçš„åˆ†å­æ€åœ¨çƒ­åŠ›å­¦ä¸Šæ˜¯äºšç¨³çš„ï¼Œå®¹æ˜“è‡ªå‘è§£ç¦»ã€‚"
                )

        final_prompt = f"""
        ä½ æ˜¯ä¸€åä¸¥è°¨çš„è®¡ç®—åŒ–å­¦å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„ã€å®¢è§‚äº‹å®æ•°æ®ã€‘æ’°å†™æœ€ç»ˆå®éªŒæŠ¥å‘Šã€‚

        !!! ä¸¥é‡è­¦å‘Š !!!
        ä½ å¿…é¡» **ä¸¥æ ¼å¿ å®** äºä»¥ä¸‹ JSON æ•°æ®ã€‚
        - **ä¸¥ç¦ç¼–é€ ** ä»»ä½•æ•°å­—ã€‚
        - **ä¸¥ç¦ç¼–é€ ** å¸é™„ä½ç‚¹åç§°ï¼ˆä»¥ `actual_site_type` ä¸ºå‡†ï¼‰ã€‚
        
        **ç”¨æˆ·è¯·æ±‚:** {state['user_request']}

        **æœ€ä½³å¸é™„æ„å‹æ•°æ®:**
        ```json
        {data_str}
        ```

        {diss_warning_context}

        **åˆå§‹è§„åˆ’:**
        ```json
        {plan_str}
        ```

        **æ’°å†™è¦æ±‚:**
        1.  **ç»“è®º:** ç›´æ¥å›ç­”ç”¨æˆ·è¯·æ±‚ã€‚
        2.  **æ•°æ®æ”¯æ’‘:** åˆ—å‡º `most_stable_energy_eV` (ä¿ç•™3ä½å°æ•°) å’Œ `final_bond_distance_A`ã€‚
        3.  **å‡ ä½•ç»†èŠ‚:** æè¿° `bonded_surface_atoms` ä¸­çš„åŸå­å’Œè·ç¦»ã€‚
        4.  **ä½ç‚¹çº æ­£:** å¦‚æœ `actual_site_type` ä¸ `planned_site_type` ä¸ç¬¦ï¼Œæ˜ç¡®æŒ‡å‡ºå‘ç”Ÿäº†â€œä½ç‚¹æ»‘ç§»â€ã€‚
        5.  **åŒ–å­¦çŠ¶æ€åˆ¤å®š (é‡è¦):** è¯·æ£€æŸ¥ JSON ä¸­çš„ `bond_change_count` å’Œ `reaction_detected` å­—æ®µï¼š
            - **å®Œç¾å¸é™„**: å¦‚æœ `bond_change_count == 0`ï¼Œè¯·æŠ¥å‘Šä¸ºâ€œåˆ†å­ä»¥å®Œæ•´æ„å‹ç¨³å®šå¸é™„â€ã€‚
            - **å¼‚æ„åŒ–/é‡æ’**: å¦‚æœ `bond_change_count > 0` ä½† `is_dissociated == False`ï¼Œè¯·ç‰¹åˆ«å¼ºè°ƒï¼šâ€œå¸é™„ç‰©åœ¨è¡¨é¢å‘ç”Ÿäº† **åˆ†å­å†…é‡æ’/å¼‚æ„åŒ–**ï¼ˆé”®å˜åŒ–æ•°: {{bond_change_count}}ï¼‰ï¼Œå½¢æˆäº†æ›´ç¨³å®šçš„æ–°æ„å‹ã€‚â€è¿™åº”è¢«è§†ä¸ºä¸€ä¸ªé‡è¦çš„åŒ–å­¦å‘ç°ã€‚
            - **è§£ç¦»**: å¦‚æœ `is_dissociated == True`ï¼Œè¯·æŠ¥å‘Šä¸ºâ€œå¸é™„ç‰©å‘ç”Ÿäº†è§£ç¦»â€ã€‚
        6. **ç§‘å­¦å®Œæ•´æ€§ä¸çƒ­åŠ›å­¦è­¦å‘Š (è‡³å…³é‡è¦):**
            - å¦‚æœæä¾›äº†ã€ä¸¥é‡çƒ­åŠ›å­¦è­¦å‘Šæ•°æ®ã€‘ï¼Œä½ å¿…é¡»åœ¨æŠ¥å‘Šçš„â€œç»“è®ºâ€æˆ–â€œè®¨è®ºâ€éƒ¨åˆ†ä»¥é†’ç›®çš„æ–¹å¼æŒ‡å‡ºï¼š
              â€œå°½ç®¡æ‰¾åˆ°äº†ç¨³å®šçš„åˆ†å­å¸é™„æ€ï¼Œä½†è®¡ç®—æ˜¾ç¤ºè¯¥åˆ†å­åœ¨è¯¥è¡¨é¢å‘ç”Ÿè§£ç¦»åœ¨çƒ­åŠ›å­¦ä¸Šæ›´æœ‰åˆ©ï¼ˆèƒ½é‡ä½ X eVï¼‰ã€‚å› æ­¤ï¼ŒæŠ¥å‘Šçš„æ„å‹å¯èƒ½ä»…åœ¨åŠ¨åŠ›å­¦ä¸Šç¨³å®šï¼ˆäºšç¨³æ€ï¼‰ã€‚â€
            - ä¸¥ç¦éšç’è¿™ä¸€äº‹å®ï¼Œè¿™å…³ä¹ç§‘å­¦è¯šä¿¡ã€‚
        """
    else:
        fail_reason = last_analysis.get("message", "æœªæ‰¾åˆ°ç¨³å®šæ„å‹ã€‚")
        final_prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªé”™è¯¯æŠ¥å‘ŠåŠ©æ‰‹ã€‚
        ä»»åŠ¡ï¼šç¤¼è²Œåœ°å‘ŠçŸ¥ç”¨æˆ·ï¼Œåœ¨ç»è¿‡å¤šæ¬¡å°è¯•åï¼Œæœªèƒ½æ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„ç¨³å®šå¸é™„æ„å‹ã€‚
        é”™è¯¯æ—¥å¿—ï¼š"{fail_reason}"
        è¯·å»ºè®®ç”¨æˆ·æ£€æŸ¥ SMILES æˆ–æ›´æ¢è¡¨é¢æ¨¡å‹ã€‚ä¸¥ç¦æé€ ç»“æœã€‚
        """

    # 4. è°ƒç”¨ LLM
    response = llm.invoke([HumanMessage(content=final_prompt)])
    
    print("--- ğŸ æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆå®Œæ¯• ---")
    return {"messages": [AIMessage(content=response.content)]}

# --- 4. å®šä¹‰å›¾çš„é€»è¾‘æµ (Edges) ---
def route_after_validation(state: AgentState) -> str:
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 1 (éªŒè¯å™¨) ---")
    if state.get("validation_error"):
        print(f"--- å†³ç­–: æ–¹æ¡ˆå¤±è´¥ï¼Œè¿”å›è§„åˆ’ ---")
        return "planner"
    
    # è·¯ç”±é€»è¾‘
    plan_json = state.get("plan", {})
    solution = plan_json.get("solution", {})
    if solution.get("action") == "terminate":
        print(f"--- å†³ç­–: Planner è¯·æ±‚ç»ˆæ­¢ï¼Œå‰å¾€æœ€ç»ˆåˆ†ææŠ¥å‘Š ---")
        return "final_analyzer"  # è·³è¿‡ Tool Executorï¼Œç›´æ¥å»å†™æŠ¥å‘Š
    
    else:
        print(f"--- å†³ç­–: æ–¹æ¡ˆé€šè¿‡ï¼Œå‰å¾€æ‰§è¡Œ ---")
        return "tool_executor"

def route_after_analysis(state: AgentState) -> str:
    """
    ç®€åŒ–çš„è·¯ç”±å™¨ï¼šç”Ÿæˆå¯Œå«ä¿¡æ¯çš„å†å²è®°å½•ï¼Œå¹¶å†³å®šä¸‹ä¸€æ­¥æ–¹å‘ã€‚
    æ³¨æ„ï¼šä¸è¦åœ¨æ­¤å¤„æ›´æ–° state["best_result"]ï¼Œè¯¥æ“ä½œå·²åœ¨ tool_executor ä¸­å®Œæˆã€‚
    """
    print("--- ğŸ¤” Python å†³ç­–åˆ†æ”¯ 3 (åˆ†æå™¨) ---")
    current_history = state.get("history", [])
    
    try:
        analysis_data = json.loads(state.get("analysis_json", "{}"))
        status = analysis_data.get("status")
        
        # æå–è§„åˆ’æè¿°
        plan = state.get("plan", {}).get("solution", {})
        plan_desc = f"{plan.get('site_type')} @ {plan.get('surface_binding_atoms')} (Index {plan.get('adsorbate_binding_indices')})"
        
        if status == "fatal_error":
            state["history"].append(f"ã€è‡´å‘½é”™è¯¯ã€‘ æ–¹æ¡ˆ: {plan_desc} -> {analysis_data.get('message')}")
            return "end"

        # 1. æå–å…³é”®æŒ‡æ ‡
        energy = analysis_data.get("most_stable_energy_eV", "N/A")
        bond_change = analysis_data.get("bond_change_count", 0)
        is_dissociated = analysis_data.get("is_dissociated", False)
        
        # 2. [å…³é”®å¢å¼º] æå–ä½ç‚¹æ»‘ç§»ä¿¡æ¯
        # è¿™èƒ½å‘Šè¯‰ Plannerï¼š"ä½ åŸæœ¬æƒ³å» Bridgeï¼Œä½†å®é™…å»äº† Hollow"
        # æå–ä½ç‚¹åˆ†ææ•°æ®
        site_info = analysis_data.get("site_analysis", {})
        actual_site = site_info.get("actual_site_type", "unknown")
        planned_site = site_info.get("planned_site_type", "unknown")
        
        # å¤„ç†åŒ–å­¦æ»‘ç§»
        is_chem_slip = site_info.get("is_chemical_slip", False)
        planned_syms = site_info.get("planned_symbols", [])
        actual_syms = site_info.get("actual_symbols", [])

        site_msg = f"ä½ç‚¹: {actual_site} ({','.join(actual_syms)})"

        # å¼ºåŒ–æ»‘ç§»çš„è´Ÿåé¦ˆ
        if is_chem_slip:
            # æå…¶å¼ºçƒˆåœ°å‘ŠçŸ¥ Plannerï¼šåŸè®¡åˆ’æ˜¯å¤±è´¥/ä¸ç¨³å®šçš„
            # å°† planned_syms è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œå¦‚ "Cu-Pd-Pd"
            planned_str = "-".join(planned_syms)
            actual_str = "-".join(actual_syms)
            
            site_msg = (
                f"âš ï¸ã€ä¸ç¨³å®šä½ç‚¹è­¦å‘Šã€‘âš ï¸: "
                f"è§„åˆ’çš„ {planned_site} ({planned_str}) ä¸ç¨³å®šï¼Œå¸é™„ç‰©è‡ªå‘æ»‘ç§»åˆ°äº† {actual_site} ({actual_str})ã€‚"
                f"è¿™æ„å‘³ç€ {planned_str} å¯¹è¯¥å¸é™„ç‰©äº²å’ŒåŠ›ä¸è¶³ï¼Œåç»­è¯·**ç¦æ­¢**å†æ¬¡æµ‹è¯• {planned_str} ç±»ä½ç‚¹ï¼"
            )
        
        elif actual_site != "unknown" and planned_site != "unknown" and actual_site != planned_site:
            # æ™®é€šè­¦å‘Šï¼šåªæ˜¯å‡ ä½•å˜äº† (å¦‚ hollow -> ontopï¼Œä½†åŸå­æ²¡å˜)
            site_msg = f"âš ï¸ å‡ ä½•æ»‘ç§»: {planned_site} -> {actual_site}"

        # 3. æ„å»ºå†å²æ¡ç›®
        if status == "success":
            if is_dissociated:
                res_str = "âŒ åˆ†å­è§£ç¦»"
            elif bond_change > 0:
                res_str = f"âš ï¸ åˆ†å­å†…é‡æ’(BC={bond_change})"
            else:
                res_str = "âœ… å®Œç¾å¸é™„"
                
            # æ ¼å¼ï¼š[ç»“æœ] æ–¹æ¡ˆ -> å®é™…ä½ç‚¹ | èƒ½é‡
            history_entry = (
                f"ã€{res_str}ã€‘ {plan_desc} "
                f"-> {site_msg} | "
                f"E={energy:.3f} eV"
            )
        else:
            history_entry = f"ã€è®¡ç®—å¤±è´¥ã€‘ {plan_desc} -> åŸå› : {analysis_data.get('message')}"
            
        current_history.append(history_entry)

    except Exception as e:
        current_history.append(f"å†å²è®°å½•ç”Ÿæˆå¼‚å¸¸: {e}")

    # æ›´æ–°å†å²è®°å½•
    state["history"] = current_history

    # 4. å†³ç­–é€»è¾‘
    if len(current_history) >= MAX_RETRIES:
        print(f"--- å†³ç­–: å·²è¾¾åˆ° {len(current_history)} æ¬¡å°è¯•ä¸Šé™ã€‚æµç¨‹ç»“æŸã€‚ ---")
        return "end"
    
    return "planner"

# --- 5. æ„å»ºå¹¶ç¼–è¯‘å›¾ (Graph) ---
def get_agent_executor():
    """ æ„å»ºå¹¶ç¼–è¯‘ Adsorb-Agent çŠ¶æ€æœºå›¾ã€‚"""
    workflow = StateGraph(AgentState)
    workflow.add_node("pre_processor", pre_processor_node)
    workflow.add_node("planner", solution_planner_node)
    workflow.add_node("plan_validator", plan_validator_node) 
    workflow.add_node("tool_executor", tool_executor_node)
    workflow.add_node("final_analyzer", final_analyzer_node)
    workflow.set_entry_point("pre_processor")
    workflow.add_edge("pre_processor", "planner")
    workflow.add_edge("planner", "plan_validator")
    workflow.add_edge("tool_executor", "final_analyzer")
    workflow.add_conditional_edges(
        "plan_validator",
        route_after_validation,
        {"tool_executor": "tool_executor", "planner": "planner"}
    )
    workflow.add_conditional_edges(
        "final_analyzer",
        route_after_analysis,
        {"planner": "planner", "end": END}
    )
    return workflow.compile()

# --- 6. è¿è¡Œç¨‹åº ---
def _prepare_initial_state(smiles: str, slab_path: str, user_request: str) -> AgentState:
    return {
        "smiles": smiles,
        "slab_path": slab_path,
        "surface_composition": None,
        "user_request": user_request,
        "plan": None,
        "validation_error": None,
        "messages": [HumanMessage(content=f"SMILES: {smiles}\nSLAB: {slab_path}\nREQUEST: {user_request}")],
        "analysis_json": None,
        "history": [],
        "best_result": None,
        "best_dissociated_result": None,
        "attempted_keys": [],
        "available_sites_description": None
    }

def parse_args():
    parser = argparse.ArgumentParser(description="Run the Adsorb-Agent.")
    parser.add_argument("--smiles", type=str, required=True, help="SMILES string.")
    parser.add_argument("--slab_path", type=str, required=True, help="Path to the slab .xyz file.")
    parser.add_argument("--user_request", type=str, default="Find a stable adsorption configuration.", help="User's request.")
    return parser.parse_args()

def main_cli():
    args = parse_args()
    if not os.path.exists('./outputs'):
        os.makedirs('./outputs')
    initial_state = _prepare_initial_state(args.smiles, args.slab_path, args.user_request)
    
    agent_executor = get_agent_executor()
    print("\n--- ğŸš€ Adsorb-Agent å·²å¯åŠ¨ ---\n")
    final_state = None

    config = {"recursion_limit": 30}

    for chunk in agent_executor.stream(initial_state, config=config, stream_mode="values"):
        final_state = chunk
        if "messages" in final_state and final_state["messages"]:
            last_message = final_state["messages"][-1]
            if isinstance(last_message, (AIMessage, ToolMessage)):
                print("\n---")
                print(f"[{last_message.type}]")
                print(last_message.content)
                print("---\n")
    print("\n--- ğŸ Adsorb-Agent ä»»åŠ¡å®Œæˆ ---\n")
    print("æœ€ç»ˆåˆ†ææŠ¥å‘Š:")
    if final_state and "messages" in final_state:
        for msg in reversed(final_state["messages"]):
            if isinstance(msg, AIMessage):
                print(msg.content)
                break
        else:
             print("æœªæ‰¾åˆ°æœ€ç»ˆ AI æ¶ˆæ¯ã€‚")

if __name__ == '__main__':
    exec_globals = builtins.__dict__.copy()
    exec_globals.update({
        "np": np, "pd": pd, "scipy": scipy, "sklearn": sklearn, "math": math,
        "ase": ase, "autoadsorbate": autoadsorbate, "torch": torch, "mace": mace,
    })
    
    main_cli()